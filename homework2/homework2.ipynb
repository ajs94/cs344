{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 344 HW2\n",
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam Probability:  0.466103896103896\n",
      "Nonzero word probabilities:\n",
      "\t{'I': 0.99, 'am': 0.99, 'do': 0.27272727272727276, 'not': 0.99, 'like': 0.27272727272727276, 'green': 0.01, 'eggs': 0.01, 'and': 0.01, 'ham': 0.01}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "A spam filter based off http://www.paulgraham.com/spam.html\n",
    "For CS 344 at Calvin College\n",
    "\n",
    "@student: ajs94\n",
    "@version March 7, 2019\n",
    "'''\n",
    "\n",
    "\n",
    "class Filter:\n",
    "\n",
    "    def __init__(self, bad_corpus, good_corpus, text):\n",
    "        self.spam_corpus = self.sentences_to_corpus(bad_corpus)\n",
    "        self.good_corpus = self.sentences_to_corpus(good_corpus)\n",
    "        self.combined_corpus = text\n",
    "        self.corpus_len = 0\n",
    "        self.corpus_counts = self.hash_words()\n",
    "        self.corpus_probs = {}\n",
    "\n",
    "    # change a list of sentences into a list of just words\n",
    "    def sentences_to_corpus(self, text):\n",
    "        corpus = []\n",
    "        for sentence in text:\n",
    "            for word in sentence:\n",
    "                corpus.append(word)\n",
    "        return corpus\n",
    "\n",
    "    # find the number of occurrences of each word\n",
    "    def hash_words(self):\n",
    "        word_dict = {}\n",
    "        for sentence in self.combined_corpus:\n",
    "            for word in sentence:\n",
    "                if word not in word_dict.keys():\n",
    "                    word_dict[word] = 0\n",
    "                self.corpus_len += 1\n",
    "                word_dict[word] += 1\n",
    "        return word_dict\n",
    "\n",
    "    def evaluate(self):\n",
    "        # print(self.spam_corpus)\n",
    "        # print(self.good_corpus)\n",
    "        # print(self.corpus_counts)\n",
    "        # print(self.combined_corpus)\n",
    "\n",
    "        prob = 0\n",
    "        for sentence in self.combined_corpus:\n",
    "            for word in sentence:\n",
    "                g = 0\n",
    "                b = 0\n",
    "                if word in self.good_corpus:\n",
    "                    g = 2 * self.corpus_counts[word]\n",
    "                if word in self.spam_corpus:\n",
    "                    b = self.corpus_counts[word]\n",
    "\n",
    "                if g + b >= 1:\n",
    "                    temp = max(0.01,\n",
    "                            min(0.99, min(1.0, b / len(self.spam_corpus)) /\n",
    "                            (min(1.0, g / len(self.good_corpus)) +\n",
    "                            min(1.0, b / len(self.spam_corpus)))))\n",
    "                    prob += temp\n",
    "                    self.corpus_probs[word] = temp\n",
    "        return prob / self.corpus_len\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    spam_corpus = [[\"I\", \"am\", \"spam\", \"spam\", \"I\", \"am\"], [\"I\", \"do\", \"not\", \"like\", \"that\", \"spamiam\"]]\n",
    "    ham_corpus = [[\"do\", \"i\", \"like\", \"green\", \"eggs\", \"and\", \"ham\"], [\"i\", \"do\"]]\n",
    "    sample_mail = [[\"I\", \"am\", \"sam\", \"sam\", \"I\", \"am\"], [\"I\", \"do\", \"not\", \"like\", \"green\", \"eggs\", \"and\", \"ham\"]]\n",
    "    # sample_mail = [[\"I\", \"am\", \"spam\", \"spam\", \"I\", \"am\"], [\"I\", \"do\", \"not\", \"like\", \"that\", \"spamiam\"]]\n",
    "    # sample_mail = [[\"Sample\", \"message\", \"with\", \"nothing\", \"in\", \"common\"], [\"Idk\", \"what\", \"else\", \"to\", \"say\"]]\n",
    "\n",
    "    filter = Filter(spam_corpus, ham_corpus, sample_mail)\n",
    "    print(\"Spam Probability: \", filter.evaluate())\n",
    "    print(\"Nonzero word probabilities:\\n\\t\" + str(filter.corpus_probs))\n",
    "\n",
    "    '''\n",
    "    This approach is Bayesian in that it determines the probabilities of individual words and uses\n",
    "        them to determine the overall probability that an email is spam ae th conditional probability that\n",
    "        if words are spam then email is spam.\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    b. We have 4 T/F variables in the distribution so 2^4 = 16 independent values.\n",
    "    c. We have 9 values possible in the Bayesian network. Cloudy has 1, rain and sprinkler each have 2, and wet grass has 4.\n",
    "    d. ->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False: 0.5, True: 0.5\n",
      "False: 0.9, True: 0.1\n",
      "False: 0.952, True: 0.0476\n",
      "False: 0.01, True: 0.99\n",
      "False: 0.639, True: 0.361\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This module implements the Bayesian network shown in the text, Figure 14.12.\n",
    "It's taken from the AIMA Python code.\n",
    "\n",
    "@student: ajs94\n",
    "@version March 8, 2019\n",
    "'''\n",
    "\n",
    "from probability import BayesNet, enumeration_ask, elimination_ask, gibbs_ask\n",
    "\n",
    "# Utility variables\n",
    "T, F = True, False\n",
    "\n",
    "# From AIMA code (probability.py) - Fig. 14.2 - burglary example\n",
    "weather = BayesNet([\n",
    "    ('Cloudy', '', 0.5),\n",
    "    ('Sprinkler', 'Cloudy', {T: 0.1, F: 0.5}),\n",
    "    ('Rain', 'Cloudy', {T: 0.8, F: 0.2}),\n",
    "    ('WetGrass', 'Sprinkler Rain', {(T, T): 0.99, (T, F): 0.9, (F, T): 0.9, (F, F): 0.0})\n",
    "    ])\n",
    "\n",
    "\n",
    "# i.        P(Cloudy) = 0.5\n",
    "#           Given from info\n",
    "#           = <0.5, 0.5>\n",
    "print(enumeration_ask('Cloudy', dict(), weather).show_approx())\n",
    "\n",
    "# ii.       P(Sprinkler | cloudy) = 0.1\n",
    "#           Given from info\n",
    "#           = <0.1, 0.9>\n",
    "print(enumeration_ask('Sprinkler', dict(Cloudy=T), weather).show_approx())\n",
    "\n",
    "# iii.      P(Cloudy | the sprinkler is running and it’s not raining)\n",
    "#           = a * P(Sprinkler, -Rain|Cloudy) * P(Cloudy)\n",
    "#           = a * 0.1 * 0.2 * 0.5\n",
    "#           = a * <0.01, .2>\n",
    "#           = <0.0476, 0.952>\n",
    "print(enumeration_ask('Cloudy', dict(Sprinkler=T, Rain=F), weather).show_approx())\n",
    "\n",
    "# iv.       P(WetGrass | it’s cloudy, the sprinkler is running and it’s raining) = 0.99\n",
    "#           Given from info\n",
    "#           = <0.01, 0.99>\n",
    "print(enumeration_ask('WetGrass', dict(Cloudy=T, Sprinkler=T, Rain=T), weather).show_approx())\n",
    "\n",
    "# v.        P(Cloudy | -WestGrass)\n",
    "#           = a * ...?\n",
    "#           I have no idea how to start/work through this...\n",
    "#           = <0.361, 0.639>\n",
    "print(enumeration_ask('Cloudy', dict(WetGrass=F), weather).show_approx())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
